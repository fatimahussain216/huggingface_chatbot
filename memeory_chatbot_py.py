# -*- coding: utf-8 -*-
"""memeory_chatBot.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10p8XT8Y8muYI4nZu3VlVP8t58Lpy-iga
"""


from langchain_huggingface import ChatHuggingFace
from langchain_huggingface import HuggingFaceEndpoint
import streamlit as st
import os
def bot():

    

    api_key = st.secrets["HUGGING_FACE_API_KEY"]
    llm = HuggingFaceEndpoint(
        repo_id="google/gemma-2-2b-it",
        task="text-generation",
        huggingfacehub_api_token=api_key
    )

    model = ChatHuggingFace(
        llm=llm,
        verbose=True
    )

    return model





    #model UI
st.set_page_config(page_title="Chat Bot",page_icon="ðŸ¤–")
st.title(" Chat Bot ")
st.markdown("This is a chat bot")
st.markdown("Enter your query below")
if "history" not in st.session_state:
    st.session_state["history"] = []

user_input=st.text_input("Enter your query")
with st.spinner("wait generate the answer"):
    model = bot()
    ans=model.invoke(user_input)
    st.success("ans generate")
    ai_ans=st.write(ans.content)
    
    st.session_state["history"].append((user_input, ai_ans))

for i, (user_q, bot_a) in enumerate(st.session_state["history"]):
    st.markdown(f"**You:** {user_input}")
    st.markdown(f"**Bot:** {ai_ans}")
